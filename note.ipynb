{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ll be creating a chat assistant that utilizes Retrieval Augmented Generation (RAG) to answer questions based on a Wikipedia page of your choice. RAG has proven to be an effective method for reducing hallucinations and providing large language models (LLMs) with up-to-date knowledge without the need for retraining. The end-to-end workflow of the chat assistant can be seen \n",
    "<img src='Capture.png' width=500 height=500>\n",
    "You will employ the ReAct (Reasoning and Act) prompting framework. This framework assists the agent in reasoning about tool usage, observing the outcomes of the tool usage, and then responding appropriately to answer the question, as shown below:\n",
    "<img src='Capture2.png' width=500 height=500>\n",
    "\n",
    "You’ll use Python modules in this project to build your chat assistant. Therefore, some template .py files are provided in the Visual Studio Code, available on the right side of the workspace:\n",
    "\n",
    "utils.py: This file will be used to read the OpenAI API key, allowing you to use the ChatGPT API from OpenAI.\n",
    "\n",
    "index_wikipages.py: This file will be used to load Wikipedia pages of your choice into memory and index them, allowing your agent to search through them.\n",
    "\n",
    "chat_agent.py: This file contains a script that creates a ReAct (Reason and Act) agent with a chat UI. The ReAct agent uses LLMs from OpenAI to answer complex questions about a topic of your choice by searching the relevant Wikipedia page.\n",
    "\n",
    "In this task, you’ll create a script to read your OpenAI API key that will allow you to use the ChatGPT API. Make sure you have an OpenAI API key with some account credit when completing this task.\n",
    "\n",
    "To obtain the OpenAI API key, see the Educative Answer on obtaining a GPT-3 API Key.\n",
    "\n",
    "To complete this task, follow these steps:\n",
    "\n",
    "Add your OpenAI API key to the apikeys.yml file located in the /usercode/ directory.\n",
    "\n",
    "Go to the /usercode/utils.py file and import the following modules:\n",
    "\n",
    "os: This module allows interactions with the operating system.\n",
    "\n",
    "yaml: This module lets you parse .yml files.\n",
    "\n",
    "Write the utils.py script to read the API key from the apikeys.yml file created in step 1.\n",
    "\n",
    "Finally, run the utils.py script in the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the upcoming tasks, you’ll be writing a script to index Wikipedia pages. You will be working on the index_wikipages.py file, so make sure you have the script open while reading this.\n",
    "\n",
    "To begin, you'll import all the necessary modules. Please read the library, class, and function descriptions carefully, because they provide hints on how to import them.\n",
    "\n",
    "To complete this task, import the following libraries:\n",
    "\n",
    "llama_index: A library that provides a framework for building LLM-powered applications.\n",
    "\n",
    "WikipediaReader: A module from llama_index.readers.wikipedia used to read and retreive Wikipedia pages.\n",
    "\n",
    "VectorStoreIndex: A class from llama_index.core.indices.vector_store used to create an in-memory vector store.\n",
    "\n",
    "SentenceSplitter: A module from llama_index.core.node_parser to split text during preprocessing.\n",
    "\n",
    "OpenAIPydanticProgram: A class from llama_index.program.openai that lets you get a structured output from a call to an OpenAI model.\n",
    "\n",
    "get_apikey: A function from utils to read your OpenAI API key from the apikeys.yml file. Remember that you created these in Task 1.\n",
    "\n",
    "pydantic: A library that provides a framework for data validation.\n",
    "\n",
    "openai: A library that allows you to use the large language models from OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you’ll develop a script to index Wikipedia pages. This will allow the conversational agent to let users request the indexing of their chosen Wikipedia pages into the agent’s knowledge base. Ensure you have the index_wikipages.py script open as you proceed with this task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The indexing will facilitate users in fetching real-time data from the indexed pages via the conversational agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete this task, follow these steps:\n",
    "\n",
    "Create a class named WikiPageList that defines a list data structure.\n",
    "\n",
    "Develop a function named wikipage_list that uses the ChatGPT API in conjunction with WikiPageList to produce a structured output from your input. This function should accept your Wikipedia page requests and return them as a list. For example, if you say, “please index: London, Birmingham, New York,” wikipage_list will produce [\"London\", \"Birmingham\", \"New York\"]. This resulting list then serves as the input for subsequent functions, guiding them on which Wikipedia pages to index.\n",
    "\n",
    "Assign the OpenAI API key using the get_apikey() function that you previously defined.\n",
    "\n",
    "Create a prompt template to guide the ChatGPT model toward delivering the desired list output. Fill in the blanks to complete the prompt template.\n",
    "\n",
    "Initialize an OpenAIPydanticProgram object with prompt_template_str and WikiPageList."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you’ll define a function, create_wikidocs(), to load the Wikipedia pages into an in-memory document store. You will use the load_data() function from the WikipediaReader class.\n",
    "\n",
    "To complete this task, follow these steps:\n",
    "\n",
    "Initialize a WikipediaReader class' object.\n",
    "\n",
    "Use this object to call the load_data() method in order to load the specified Wikipedia pages and store them as documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create_wikidocs functions, which you wrote in the previous tasks, to load Wikipedia pages into the in-memory document store. Afterward, an index will be created, which essentially acts as an in-memory vector store. Keep in mind that this vector store is essential for performing search and retrieval operations on the indexed Wikipedia pages.\n",
    "\n",
    "Note: Indexing is a crucial step that enables semantic searches on the Wikipedia pages by transforming text chunks into numerical embeddings encapsulating semantic meanings.\n",
    "\n",
    "The end-to-end process involves capturing Wikipedia pages’ content, breaking the content into text chunks, and indexing these chunks in the vector store (in memory). During indexing, text chunks are converted into embeddings using the sentence embedding model BAAI/bge-small-en.\n",
    "\n",
    "Note: Embeddings are numerical representations of the text chunks that preserve the semantic meaning.\n",
    "\n",
    "To complete this task, follow these steps:\n",
    "\n",
    "In order to split sentences, create an object of the SentenceSplitter class defining the chunk_size and chunk_overlap. Set these to 150 tokens and 45 tokens, respectively, as these values will suffice for our needs.\n",
    "\n",
    "Use the get_nodes_from_documents() function to parse the documents into nodes.\n",
    "\n",
    "Use the VectorStoreIndex class to create an index object, essentially an in-memory vector store containing user-selected Wikipedia pages processed based on the specifications defined in the parser object created in the previous step.\n",
    "\n",
    "Run index_wikipages.py within the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### creating the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you’ll define the final function, create_index, within the index_wikipages.py script. This function will use the wikipage_list and create_wikidocs functions, which you wrote in the previous tasks, to load Wikipedia pages into the in-memory document store. Afterward, an index will be created, which essentially acts as an in-memory vector store. Keep in mind that this vector store is essential for performing search and retrieval operations on the indexed Wikipedia pages.\n",
    "\n",
    "Note: Indexing is a crucial step that enables semantic searches on the Wikipedia pages by transforming text chunks into numerical embeddings encapsulating semantic meanings.\n",
    "\n",
    "The end-to-end process involves capturing Wikipedia pages’ content, breaking the content into text chunks, and indexing these chunks in the vector store (in memory). During indexing, text chunks are converted into embeddings using the sentence embedding model BAAI/bge-small-en.\n",
    "\n",
    "Note: Embeddings are numerical representations of the text chunks that preserve the semantic meaning.\n",
    "\n",
    "To complete this task, follow these steps:\n",
    "\n",
    "In order to split sentences, create an object of the SentenceSplitter class defining the chunk_size and chunk_overlap. Set these to 150 tokens and 45 tokens, respectively, as these values will suffice for our needs.\n",
    "\n",
    "Use the get_nodes_from_documents() function to parse the documents into nodes.\n",
    "\n",
    "Use the VectorStoreIndex class to create an index object, essentially an in-memory vector store containing user-selected Wikipedia pages processed based on the specifications defined in the parser object created in the previous step.\n",
    "\n",
    "Run index_wikipages.py within the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import libraries for chat assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you’ll import the libraries you need for the chat assistant.\n",
    "\n",
    "\n",
    "Ensure that you have the chat_agent.py file open and import the following libraries:\n",
    "\n",
    "QueryEngineTool: This class from the llama_index.core.tools.query_engine module allows you to initialize a query engine tool integrated with your Wikipedia search engine. The ReAct agent utilizes this query engine tool to address user queries related to a Wikipage.\n",
    "\n",
    "ToolMetadata: This class from the llama_index.core.tools.types module lets you attribute metadata to the tool, mainly for tracking purposes.\n",
    "\n",
    "ReActAgent: This class from the the llama_index.core.agent.react.base module is used for creating a ReAct agent.\n",
    "\n",
    "OpenAI: This class from the llama_index.llms.openai.base module serves as a wrapper for the ChatGPT API, making interactions smoother.\n",
    "\n",
    "chainlit: This library is instrumental in constructing your chat agent’s user interface and interactions.\n",
    "\n",
    "Select: This class from the chainlit.input_widgets module facilitates the initialization of a settings menu where users can make selections from given options.\n",
    "\n",
    "TextInput: This class from the chainlit.input_widgets module aids in setting up a menu that provides the option for users to input text.\n",
    "\n",
    "openai: This library provides access to OpenAI’s ChatGPT interface.\n",
    "\n",
    "create_index: This is the function you delineated earlier to index Wikipedia pages as chosen by the user. It’s accessible from the index_wikipages module.\n",
    "\n",
    "get_apikey: You’ve previously outlined this function to fetch your OpenAI API key. It can be imported from the utils module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the settings menu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you’ll initialize the settings menu for your chat assistant application. In this menu, the app user will perform two key actions:\n",
    "\n",
    "Select a model to use from OpenAI’s ChatGPT API.\n",
    "\n",
    "Enter the name of the Wikipedia pages to index for search.\n",
    "\n",
    "To complete this task, ensure you have chat_agent.py open and in there, perform the following steps:\n",
    "\n",
    "Use the Select class to set up a selection panel, offering users a choice of OpenAI models. Specify the list  [\"gpt-3.5-turbo\"] of OpenAI GPT models in the values argument. The id argument is used to reference the user’s selection later in our script; we’ll assign it \"MODEL\" as a value. The label provides guidance to the user at the top of the panel.\n",
    "\n",
    "Use the TextInput class to allow users to specify their Wikipedia page request. Note that the prompt template you set up earlier means that the user should specify their Wikipedia pages in the following manner: “Please index: Wikipedia page, Wikipedia page2, etc.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the wikipedia search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you’ll create a Wikipedia search engine using the index of Wikipedia pages you’ve generated. The LlamaIndex library provides a convenient method named as_query_engine to transform the index into a search engine. You will be working in the chat_agent.py file.\n",
    "\n",
    "Note: Familiarize yourself with the function used for indexing Wikipedia pages, because you will need it to complete the task.\n",
    "\n",
    "To complete this task, use the as_query_engine method. This method is available from your index object and will configure your index to function as a Wikipedia search or query engine. The following steps show you which parameters to use with this method:\n",
    "\n",
    "Set the response_mode parameter. The response_mode parameter has various options. Select compact to ensure efficiency.\n",
    "\n",
    "Set the verbose parameter. The verbose parameter controls the extent of the output from the query engine. Set this to True for transparency.\n",
    "\n",
    "Set the similarity_top_k parameter. The similarity_top_k parameter controls the number of top text chunks retrieved that are most similar to the user’s query. Set this to 10.\n",
    "\n",
    "Taking into account the guidance from the points, complete the wikisearch_engine(index) function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the react agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you’ll set up a ReAct agent to interpret user queries. The agent determines if a tool is needed for a response, decides on the tool’s use, and evaluates its output to ensure the query is addressed. This loop continues until the query is resolved or a set iteration limit is reached. The agent has two main components:\n",
    "\n",
    "The tool(s) it uses.\n",
    "\n",
    "The LLM (large language model) that empowers it.\n",
    "\n",
    "The following image illustrates the workflow of the ReAct agent in the chat UI:\n",
    "\n",
    "\n",
    "The ReAct agent workflow demonstrated in the chat UI\n",
    "\n",
    "The ReAct agent workflow demonstrated in the chat UI\n",
    "To complete this task, ensure the chat_agent.py file is open and perform the following to define the create_react_agent function:\n",
    "\n",
    "Initialize the QueryEngineTool class. This class wraps the wikisearch_engine function that you previously defined.\n",
    "\n",
    "Instantiate an object named query_engine_tools, using the QueryEngineTool class, with the following parameters:\n",
    "\n",
    "query_engine: Set this to wikisearch_engine(index).\n",
    "\n",
    "metadata: Use the ToolMetadata class to set metadata about the tool with the parameters name as “Wikipedia Search” and description as “Useful for performing searches on the Wikipedia knowledgebase.”\n",
    "\n",
    "Use the OpenAI class as a wrapper, facilitating the ReAct agent’s access to an OpenAI model. It requires a model argument, which should be set to MODEL. This will take the user’s selected model from the settings menu.\n",
    "\n",
    "Instantiate the ReAct Agent by employing the ReActAgent class. Then, use the from_tools method to pass in essential arguments, as follows:\n",
    "\n",
    "tools: Set this to query_engine_tools.\n",
    "\n",
    "llm: Set this to llm.\n",
    "\n",
    "verbose: Set this to True for an increased transparency on the agent’s workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalize settings menu "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you’ll further develop the settings menu by ensuring that certain functions are triggered when the settings are updated. The main actions that users perform are selecting a model and specifying the Wikipedia pages to index. Your script should initiate the necessary procedures to prepare the chat agent for these user inputs.\n",
    "\n",
    "To complete this task, ensure the file chat_agent.py is open and perform the following steps:\n",
    "\n",
    "Create an asynchronous function named setup_agent that will be executed whenever the settings are updated. Use the decorator @cl.on_settings_update directly before defining this function to ensure it is triggered upon settings modification.\n",
    "\n",
    "Extract the input string from the settings panel and assign it to the variable query.\n",
    "\n",
    "Invoke the create_index() function, passing query as an argument to index the specified Wikipedia pages.\n",
    "\n",
    "Extract the user’s model selection from the settings menu and assign it to the variable MODEL.\n",
    "\n",
    "Instantiate a ReAct agent object using the create_react_agent() function, supplying MODEL as an argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script the Chat Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you’ll script user-agent interactions within a function named main, which will be activated whenever a user sends a query to the agent. The main function will be responsible for processing the user’s message and generating an appropriate response.\n",
    "\n",
    "To complete this task, ensure the chat_agent.py file is open and perform the following steps:\n",
    "\n",
    "Complete the main function and ensure it’s triggered upon receiving a message by using the @cl.on_message decorator. Remember to define the main function asynchronously using async.\n",
    "\n",
    "Use the await cl.make_async(agent.chat)(message) command to process the user’s query and formulate a response. Assign this response to a variable named response. Do this within the main function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Launching the chat Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get your chat agent up and running, you’ll need to utilize the terminal within your workspace.\n",
    "\n",
    "To complete this task, follow these steps:\n",
    "\n",
    "Within the terminal, key in the command chainlit run chat_agent.py -h. As this runs, you’ll notice messages signaling the progression of your scripts. Be patient and allow a few moments for these messages to conclude or until your screen mirrors the display in the image below.\n",
    "\n",
    "Once the script concludes its execution, direct your attention to the browser session on the right side of the workspace and give the refresh button a click. This action should usher in the display of your conversational app.\n",
    "\n",
    "Follow the instructions presented within the chat window to complete the agent setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use your chat assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you’ll test your chat agent with some trivia about the 2023 banking crisis.\n",
    "\n",
    "To complete this task, follow these steps:\n",
    "\n",
    "Index the Wikipedia page about the 2023 banking crisis by typing “please index: 2023 United States banking crisis” in the settings menu.\n",
    "\n",
    "Await the agent’s confirmation that the Wikipedia page has been indexed.\n",
    "\n",
    "Note: The actual answers may differ from the provided answers.\n",
    "\n",
    "Test the conversational agent by asking it questions about the crisis.\n",
    "\n",
    "Trivia:\n",
    "\n",
    "Which bank experienced the fastest bank run in US history in March 2023, and how much was withdrawn from it within a 10-hour span?\n",
    "\n",
    "Answer: Silicon Valley Bank (SVB) experienced the fastest bank run in US history in March 2023. $42 billion was withdrawn from it within a 10-hour span.\n",
    "\n",
    "Despite a substantial capital infusion in March, which San Francisco-based bank continued to destabilize, leading to its eventual closure and sale to JPMorgan Chase by May 1?\n",
    "\n",
    "Answer: The San Francisco-based bank that continued to destabilize, despite a substantial capital infusion in March, was First Republic Bank (FRB). It was eventually closed and sold to JPMorgan Chase by May 1.\n",
    "\n",
    "In 2023, what percentage of Silvergate Bank’s deposits were cryptocurrency-related, and which notable individual was tied to over $1 billion in deposits?\n",
    "\n",
    "Answer: In 2023, 90% of Silvergate Bank’s deposits were cryptocurrency-related. Sam Bankman-Fried was notably tied to over $1 billion in deposits.\n",
    "\n",
    "How did the surge in interest rates during 2021–2023 affect the mark-to-market price of Silvergate’s securities like mortgage-backed securities and U.S. bonds?\n",
    "\n",
    "Answer: As interest rates increased during the 2021–2023 inflation surge, the mark-to-market price of securities like mortgage-backed securities and U.S. bonds held by Silvergate decreased significantly. This change poses significant risks to the bank’s ability to continue operating, especially if they were forced to sell these securities at a lower mark-to-market price.\n",
    "\n",
    "How did the California Department of Financial Protection and Innovation respond to the bank run experienced by Silicon Valley Bank on March 10, 2023?\n",
    "\n",
    "Answer: On March 10, 2023, in response to the bank run faced by Silicon Valley Bank, the California Department of Financial Protection and Innovation (DFPI) seized SVB and placed it under the receivership of the FDIC.\n",
    "\n",
    "By early 2023, where did Signature Bank rank in terms of providing banking services to the cryptocurrency industry?\n",
    "\n",
    "Answer: By early 2023, Signature Bank had become the second largest provider of banking services to the cryptocurrency industry, trailing only Silvergate Bank.\n",
    "\n",
    "What was the name of Signature Bank’s proprietary payment network for its cryptocurrency clients, and when did it open for approved clients?\n",
    "\n",
    "Answer: The proprietary payment network of Signature Bank for its cryptocurrency clients was named \"Signet.\" It opened for approved clients in 2019.\n",
    "\n",
    "How well did the conversational agent do in responding to these questions? Feel free to experiment with other Wikipedia pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19 (main, Apr  6 2024, 17:57:55) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
